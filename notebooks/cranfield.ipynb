{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First term project (Cranfield) example solution.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "y845E0ePZqeH",
        "CwYwHs-MpD1_",
        "xJM9TfbEPCZV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfQo2UKpZ9jT"
      },
      "source": [
        "# First Term Project: Cranfield Collection\n",
        "“The Cranfield collection [...] was the pioneering test collection in allowing CRANFIELD precise quantitative measures of information retrieval effectiveness [...]. Collected in the United Kingdom starting in the late 1950s, it contains 1398 abstracts of aerodynamics journal articles, a set of 225 queries, and exhaustive relevance judgments of all (query, document) pairs.” [1, Section 8.2]\n",
        "\n",
        "Your tasks, reviewed by your colleagues and the course instructors, are the following:\n",
        "\n",
        "1.   *Implement an unsupervised ranked retrieval system*, [1, Chapter 6] which will produce a list of documents from the Cranfield collection in a descending order of relevance to a query from the Cranfield collection. You MUST NOT use relevance judgements from the Cranfield collection in your information retrieval system. Relevance judgements MUST only be used for the evaluation of your information retrieval system.\n",
        "\n",
        "2.   *Document your code* in accordance with [PEP 257](https://www.python.org/dev/peps/pep-0257/), ideally using [the NumPy style guide](https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard) as seen in the code from exercises.  \n",
        "     *Stick to a consistent coding style* in accordance with [PEP 8](https://www.python.org/dev/peps/pep-0008/).\n",
        "\n",
        "3.   *Reach at least 22% mean average precision* [1, Section 8.4] with your system on the Cranfield collection. You MUST record your score either in [the public leaderboard](https://docs.google.com/spreadsheets/d/e/2PACX-1vT0FoFzCptIYKDsbcv8LebhZDe_20GFeBAPmS-VyImlWbqET0T7I2iWy59p9SHbUe3LX1yJMhALPcCY/pubhtml) or in this Jupyter notebook. You are encouraged to use techniques for tokenization, [1, Section 2.2] document representation [1, Section 6.4], tolerant retrieval [1, Chapter 3], relevance feedback and query expansion, [1, Chapter 9] and others discussed in the course.\n",
        "\n",
        "4.   _[Upload an .ipynb file](https://is.muni.cz/help/komunikace/spravcesouboru#k_ss_1) with this Jupyter notebook to the homework vault in IS MU._ You MAY also include a brief description of your information retrieval system and a link to an external service such as [Google Colaboratory](https://colab.research.google.com/), [DeepNote](https://deepnote.com/), or [JupyterHub](https://iirhub.cloud.e-infra.cz/).\n",
        "\n",
        "[1] Manning, Christopher D., Prabhakar Raghavan, and Hinrich Schütze. [*Introduction to information retrieval*](https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf). Cambridge university press, 2008."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmpR8qpTZwyP"
      },
      "source": [
        "## Loading the Cranfield collection\n",
        "\n",
        "First, we will install [our library](https://gitlab.fi.muni.cz/xstefan3/pv211-utils) and load the Cranfield collection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inUAfc6TQMVJ"
      },
      "source": [
        "%%capture\n",
        "! pip install git+https://github.com/MIR-MU/pv211-utils.git@spring2022\n",
        "! pip install gensim==3.6.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y845E0ePZqeH"
      },
      "source": [
        "### Loading the documents\n",
        "\n",
        "Next, we will define a class named `Document` that will represent a preprocessed document from the Cranfield collection. Tokenization and preprocessing of the `title` and `body` attributes of the individual documents as well as the creative use of the `authors`, `bibliography`, and `title` attributes is left to your imagination and craftsmanship."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyAqWIQyINng"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "from pv211_utils.cranfield.entities import CranfieldDocumentBase\n",
        "\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "class Document(CranfieldDocumentBase):\n",
        "    \"\"\"\n",
        "    A preprocessed Cranfield collection document.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    document_id : str\n",
        "        A unique identifier of the document.\n",
        "    authors : list of str\n",
        "        A unique identifiers of the authors of the document.\n",
        "    bibliography : str\n",
        "        The bibliographical entry for the document.\n",
        "    title : str\n",
        "        The title of the document.\n",
        "    body : str\n",
        "        The abstract of the document.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, document_id: str, authors: str, bibliography: str, title: str, body: str):\n",
        "        super().__init__(document_id, authors, bibliography, title, body)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwnMPmFjK_FQ"
      },
      "source": [
        "We will load documents into the `documents` [ordered dictionary](https://docs.python.org/3.8/library/collections.html#collections.OrderedDict). Each document is an instance of the `Document` class that we have just defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfRrW7O6U5wb"
      },
      "source": [
        "from pv211_utils.cranfield.loader import load_documents\n",
        "\n",
        "documents = load_documents(Document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkeKUsWWWnb9"
      },
      "source": [
        "print('\\n'.join(repr(document) for document in list(documents.values())[:3]))\n",
        "print('...')\n",
        "print('\\n'.join(repr(document) for document in list(documents.values())[-3:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvsnuhT3ZZAo"
      },
      "source": [
        "document = documents['14']\n",
        "document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-zw68v5Xoh5"
      },
      "source": [
        "print(document.authors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p13FfuduZSRK"
      },
      "source": [
        "print(document.bibliography)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5bmj4WzZc9e"
      },
      "source": [
        "print(document.title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3z7ed8SZkn6"
      },
      "source": [
        "print(document.body)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwYwHs-MpD1_"
      },
      "source": [
        "### Loading the queries\n",
        "Next, we will define a class named `Query` that will represent a preprocessed query from the Cranfield collection. Tokenization and preprocessing of the `body` attribute of the individual queries is left to your craftsmanship."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaCFkMFdKjST"
      },
      "source": [
        "from pv211_utils.cranfield.entities import CranfieldQueryBase\n",
        "\n",
        "class Query(CranfieldQueryBase):\n",
        "    \"\"\"\n",
        "    A preprocessed Cranfield collection query.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    query_id : int\n",
        "        A unique identifier of the query.\n",
        "    body : str\n",
        "        The text of the query.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, query_id: int, body: str):\n",
        "        super().__init__(query_id, body)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-aAREbRMXeJ"
      },
      "source": [
        "We will load queries into the `queries` [ordered dictionary](https://docs.python.org/3.8/library/collections.html#collections.OrderedDict). Each query is an instance of the `Query` class that we have just defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qcyQUNRqRTr"
      },
      "source": [
        "from pv211_utils.cranfield.loader import load_queries\n",
        "\n",
        "queries = load_queries(Query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW-N6g3LqwPZ"
      },
      "source": [
        "print('\\n'.join(repr(query) for query in list(queries.values())[:3]))\n",
        "print('...')\n",
        "print('\\n'.join(repr(query) for query in list(queries.values())[-3:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgdHjSYIq5HV"
      },
      "source": [
        "query = queries[14]\n",
        "query"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4NGZOdOq8NF"
      },
      "source": [
        "print(query.body)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJM9TfbEPCZV"
      },
      "source": [
        "## Implementation of your information retrieval system\n",
        "Next, we will define a class named `IRSystem` that will represent your information retrieval system. Your class must define a method name `search` that takes a query and returns documents in descending order of relevance to the query.\n\nThe example implementation returns documents in decreasing order of the bag-of-words cosine similarity between the document and the query. The example implementation returns documents in decreasing order of the TF-IDF cosine similarity between the document and the query. You can use the example implementation as a basis of your system, or you can replace it with your own implementation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterable\n",
        "\n",
        "from pv211_utils.cranfield.irsystem import CranfieldIRSystemBase\n",
        "\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.matutils import cossim\n",
        "from gensim.similarities import SparseMatrixSimilarity\n",
        "from gensim.utils import simple_preprocess\n",
        "from tqdm import tqdm\n",
        "\n",
        "class IRSystem(CranfieldIRSystemBase):\n",
        "    \"\"\"\n",
        "    A system that returns documents ordered by decreasing cosine similarity.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    dictionary: Dictionary\n",
        "        The dictionary of the system.\n",
        "    index: MatrixSimilarity\n",
        "        The indexed documents.\n",
        "    index_to_document: dict of (int, Document)\n",
        "        A mapping from indexed document numbers to documents.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        document_bodies = (simple_preprocess(document.body) for document in documents.values())\n",
        "        document_bodies = tqdm(document_bodies, desc='Building the dictionary', total=len(documents))\n",
        "        dictionary = Dictionary(document_bodies)\n",
        "        document_vectors = (dictionary.doc2bow(simple_preprocess(document.body)) for document in documents.values())\n",
        "        document_vectors = tqdm(document_vectors, desc='Building the index', total=len(documents))\n",
        "        index = SparseMatrixSimilarity(document_vectors, num_docs=len(documents), num_terms=len(dictionary))\n",
        "        index_to_document = dict(enumerate(documents.values()))\n",
        "        self.dictionary = dictionary\n",
        "        self.index = index\n",
        "        self.index_to_document = index_to_document\n",
        "\n",
        "    def search(self, query: Query) -> Iterable[Document]:\n",
        "        \"\"\"The ranked retrieval results for a query.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        query : Query\n",
        "            A query.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        iterable of Document\n",
        "            The ranked retrieval results for a query.\n",
        "\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        query_vector = self.dictionary.doc2bow(simple_preprocess(query.body))\n",
        "        similarities = enumerate(self.index[query_vector])\n",
        "        similarities = sorted(similarities, key=lambda item: item[1], reverse=True)\n",
        "        for document_number, _ in similarities:\n",
        "            document = self.index_to_document[document_number]\n",
        "            yield document"
      ],
      "metadata": {
        "id": "fsebqdj8t2F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwrCzoaZhWi4"
      },
      "source": [
        "## Evaluation\n",
        "Finally, we will evaluate your information retrieval system using [the Mean Average Precision](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision) (MAP) evaluation measure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssX-nvxGu3JK"
      },
      "source": [
        "from pv211_utils.cranfield.loader import load_judgements\n",
        "from pv211_utils.cranfield.leaderboard import CranfieldLeaderboard\n",
        "from pv211_utils.cranfield.eval import CranfieldEvaluation\n",
        "\n",
        "submit_result = False\n",
        "author_name = 'Surname, Name'\n",
        "\n",
        "print('Initializing your system ...')\n",
        "system = IRSystem()\n",
        "\n",
        "evaluation = CranfieldEvaluation(system, load_judgements(queries, documents), CranfieldLeaderboard(), author_name)\n",
        "evaluation.evaluate(tqdm(queries.values(), desc='Querying your system'), submit_result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
