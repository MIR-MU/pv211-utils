{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "YaPbEXlHvd_C",
   "metadata": {
    "id": "YaPbEXlHvd_C",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CQADupStack Collection\n",
    "\n",
    "The *CQADupStack* is \"[a] Benchmark Data Set for Community Question-Answering Research\" [1] that is a part of the [*Benchmarking Information Retrieval (BEIR)*](https://github.com/beir-cellar/beir) collection.\n",
    "\n",
    "CQADupStack contains data from 12 different [*Stackexchange*](https://stackexchange.com/) subforums based on the data dump released on September 26, 2014.\n",
    "\n",
    "Your tasks, reviewed by your colleagues and the course instructors, are the following:\n",
    "\n",
    "\n",
    "\n",
    "1. *Implement a ranked retrieval system*, [1, Chapter¬†6] which will produce a list of documents from the CQADupStack collection in a descending order of relevance to a query from the CQADupStack collection.\n",
    "2. *Document your code* in accordance with [PEP 257](https://www.python.org/dev/peps/pep-0257/), ideally using [the NumPy style guide](https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard) as seen in the code from exercises.\n",
    "   *Stick to a consistent coding style* in accordance with [PEP 8](https://www.python.org/dev/peps/pep-0008/).\n",
    "3. *Reach at least 22% mean average precision* [1, Section¬†8.4] with your system on the CQADupStack collection.\n",
    "4.   _[Upload an .ipynb file](https://is.muni.cz/help/komunikace/spravcesouboru#k_ss_1) with this Jupyter notebook to the homework vault in IS MU._ You MAY also include a brief description of your information retrieval system and a link to an external service such as [Google Colaboratory](https://colab.research.google.com/), [DeepNote](https://deepnote.com/), or [JupyterHub](https://iirhub.cloud.e-infra.cz/).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[1] Hoogeveen, Doris and Verspoor, Karin M. and Baldwin, Timothy. [*CQADupStack: A Benchmark Data Set for Community Question-Answering Research*](https://dl.acm.org/doi/10.1145/2838931.2838934). ACM, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u6zDHKMAvvTt",
   "metadata": {
    "id": "u6zDHKMAvvTt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import the utility tools from the git repository.\n",
    "\n",
    "First, we will install [our library](https://github.com/MIR-MU/pv211-utils).\n",
    "\n",
    "It may be necessary to restart the runtime to get the installed packages to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c23a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install git+https://github.com/MIR-MU/pv211-utils.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I0_jZfSIwfcv",
   "metadata": {
    "id": "I0_jZfSIwfcv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define the necessary classes\n",
    "\n",
    "These will eventually represent the Queries, Documents and Relevance Judgements from the CQADupStack collection.\n",
    "\n",
    "Query and Document consist only of their IDs and bodies.\n",
    "Judgements are also just a Set of Tuples that represent pairs of relevant Document-Query combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f3f1a8-2a5b-4d3f-9e68-175909efe906",
   "metadata": {
    "id": "d3f3f1a8-2a5b-4d3f-9e68-175909efe906",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pv211_utils.beir.entities import BeirDocumentBase, BeirQueryBase, BeirJudgementBase\n",
    "from typing import Set\n",
    "\n",
    "\n",
    "class Query(BeirQueryBase):\n",
    "    \"\"\"\n",
    "    A processed query form the Beir collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query_id : int\n",
    "        The number\n",
    "    body : str\n",
    "        Text of a query\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, query_id: int, body: str):\n",
    "        super().__init__(query_id, body)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.body\n",
    "\n",
    "\n",
    "class Document(BeirDocumentBase):\n",
    "    \"\"\"\n",
    "    A processed document form the Beir collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document_id : str\n",
    "        A unique identifier of the document.\n",
    "    body : str\n",
    "        The text of the document.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, document_id: str, body: str):\n",
    "        super().__init__(document_id, body)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.body\n",
    "\n",
    "\n",
    "BeirJudgements = Set[BeirJudgementBase]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f6e32",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the datasets\n",
    "### CQADupStack contains 12 datasets that will be loaded and merged:\n",
    "- Android\n",
    "- English\n",
    "- Gaming\n",
    "- GIS\n",
    "- Mathematica\n",
    "- Physics\n",
    "- Programmers\n",
    "- Stats\n",
    "- TeX\n",
    "- Unix\n",
    "- Webmasters\n",
    "- WordPress\n",
    "\n",
    "For more details: <a href=http://nlp.cis.unimelb.edu.au/resources/cqadupstack/>CQADupStack site</a>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f2a62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/beir/util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d65f0523dd0408b843377d9c16ccdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8feb58098e514e9c93a8e9164f833259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3ea42f9ae645b8b29ddc3b0e9e711a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff9c9d932844b0da40bac28a5661e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6ed6eff8984bf3a7499dbe07e7f502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9e8e047f7c45dfb325944ebd477203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052d547e307b410a9a971a2ae40d079f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07b7fa72cbc44ac9156a1c74223ea63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cb87cd8d5845e281d61b445ee586d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a26fe00f95454b822096036db304e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47382 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befe6fae56f8408ca2b8884e39a52fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ac6a142f4d44908170603a5c705cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48605 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pv211_utils.datasets import CQADupStackDataset \n",
    "\n",
    "data = CQADupStackDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8649d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data.load_documents(document_class=Document)\n",
    "\n",
    "train_queries = data.load_train_queries(query_class=Query)\n",
    "train_judgements = data.load_train_judgements()\n",
    "\n",
    "validation_queries = data.load_validation_queries(query_class=Query)\n",
    "validation_judgements = data.load_validation_judgements()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd10d1",
   "metadata": {},
   "source": [
    "### Implementation of information retrieval system\n",
    "\n",
    "Here we will define our IR system. If you want to use your own class it must define a method name `search` that takes a query and returns documents in descending order of relevance to the query.\n",
    "\n",
    "This example returns documents in a decreasing order according to\n",
    "a [*Okapi BestMatch25+*](https://en.wikipedia.org/wiki/Okapi_BM25#Modifications) similarity score between the documents and the given query.\n",
    "\n",
    "If you wish you might use [preprocessing](https://github.com/MIR-MU/pv211-utils/tree/main/pv211_utils/preprocessing) or [ensemble](https://github.com/MIR-MU/pv211-utils/blob/developer/pv211_utils/ensembles.py) techniques from our library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e80203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pv211_utils.systems import BM25PlusSystem\n",
    "from pv211_utils.preprocessing.preprocessing import NoneDocPreprocessing, SimpleDocPreprocessing\n",
    "\n",
    "system = BM25PlusSystem(documents, SimpleDocPreprocessing())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EiuNlaI76EPe",
   "metadata": {
    "id": "EiuNlaI76EPe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate the system on a given dataset\n",
    "\n",
    "We will evaluate the IR system using the [Mean Average Precision](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision) (MAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a297dbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your system achieved **21.96% MAP score**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "You need at least **22%** to pass. üò¢"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Try playing with the preprocessing of queries and documents! üí°"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Set `submit_result = True` and write your name to the `author_name` variable to submit your result to [the leaderboard](https://docs.google.com/spreadsheets/d/e/2PACX-1vSnyvgqXDq3XPzGz3eLz_8JPwceou10HiEShI0wJ2A8vlosRZc1QhKZ10aOmmQFitv2yPAyBERD2wwx/pubhtml ). üèÜ\n",
       "\n",
       "The best submissions on the leaderboard will receive *small awards during the semester*, and some *__seriously big__ awards* after the personal check at the end of the competition (2023-04-30). Please be polite, do not spoil the game for the others, and **have fun!** üòâ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pv211_utils.beir.leaderboard import BeirLeaderboard\n",
    "from pv211_utils.beir.eval import BeirEvaluation\n",
    "\n",
    "submit_result = False\n",
    "author_name = 'Surname, Name'\n",
    "\n",
    "test_queries = data.load_test_queries(Query)\n",
    "test_judgements = data.load_test_judgements()\n",
    "\n",
    "\n",
    "evaluation = BeirEvaluation(system, test_judgements, k=10, leaderboard=BeirLeaderboard(), author_name=author_name, num_workers=8)\n",
    "evaluation.evaluate(test_queries, submit_result)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TermFrequency-InverseDocumentFrequency_example.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "97b31d6e62de2216a05dd9342162045e53cee058ed98d00a361b193ba69cab9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
