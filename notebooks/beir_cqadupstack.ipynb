{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "YaPbEXlHvd_C",
   "metadata": {
    "id": "YaPbEXlHvd_C",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CQADupStack Collection\n",
    "\n",
    "The *CQADupStack* is \"[a] Benchmark Data Set for Community Question-Answering Research\" [1] that is a part of the [*Benchmarking Information Retrieval (BEIR)*](https://github.com/beir-cellar/beir) collection.\n",
    "\n",
    "CQADupStack contains data from 12 different [*Stackexchange*](https://stackexchange.com/) subforums based on the data dump released on September 26, 2014.\n",
    "\n",
    "Your tasks, reviewed by your colleagues and the course instructors, are the following:\n",
    "\n",
    "\n",
    "\n",
    "1. *Implement a ranked retrieval system*, [1, Chapter 6] which will produce a list of documents from the CQADupStack collection in a descending order of relevance to a query from the CQADupStack collection.\n",
    "2. *Document your code* in accordance with [PEP 257](https://www.python.org/dev/peps/pep-0257/), ideally using [the NumPy style guide](https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard) as seen in the code from exercises.\n",
    "   *Stick to a consistent coding style* in accordance with [PEP 8](https://www.python.org/dev/peps/pep-0008/).\n",
    "3. *Reach at least 22% mean average precision* [1, Section 8.4] with your system on the CQADupStack collection.\n",
    "4.   _[Upload an .ipynb file](https://is.muni.cz/help/komunikace/spravcesouboru#k_ss_1) with this Jupyter notebook to the homework vault in IS MU._ You MAY also include a brief description of your information retrieval system and a link to an external service such as [Google Colaboratory](https://colab.research.google.com/), [DeepNote](https://deepnote.com/), or [JupyterHub](https://iirhub.cloud.e-infra.cz/).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[1] Hoogeveen, Doris and Verspoor, Karin M. and Baldwin, Timothy. [*CQADupStack: A Benchmark Data Set for Community Question-Answering Research*](https://dl.acm.org/doi/10.1145/2838931.2838934). ACM, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u6zDHKMAvvTt",
   "metadata": {
    "id": "u6zDHKMAvvTt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import the utility tools from the git repository.\n",
    "\n",
    "First, we will install [our library](https://github.com/MIR-MU/pv211-utils).\n",
    "\n",
    "It may be necessary to restart the runtime to get the installed packages to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c23a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install git+https://github.com/MIR-MU/pv211-utils.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I0_jZfSIwfcv",
   "metadata": {
    "id": "I0_jZfSIwfcv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define the necessary classes\n",
    "\n",
    "These will eventually represent the Queries, Documents and Relevance Judgements from the CQADupStack collection.\n",
    "\n",
    "Query and Document consist only of their IDs and bodies.\n",
    "Judgements are also just a Set of Tuples that represent pairs of relevant Document-Query combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f3f1a8-2a5b-4d3f-9e68-175909efe906",
   "metadata": {
    "id": "d3f3f1a8-2a5b-4d3f-9e68-175909efe906",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pv211_utils.beir.entities import BeirDocumentBase, BeirQueryBase, BeirJudgementBase\n",
    "from typing import Set\n",
    "\n",
    "class Query(BeirQueryBase):\n",
    "    \"\"\"\n",
    "    A processed query form the Beir collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query_id : int\n",
    "        The number\n",
    "    body : str\n",
    "        Text of a query\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, query_id: int, body: str):\n",
    "        super().__init__(query_id, body)\n",
    "\n",
    "class Document(BeirDocumentBase):\n",
    "    \"\"\"\n",
    "    A processed document form the Beir collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document_id : str\n",
    "        A unique identifier of the document.\n",
    "    body : str\n",
    "        The text of the document.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, document_id: str, body: str):\n",
    "        super().__init__(document_id, body)\n",
    "        \n",
    "BeirJudgements = Set[BeirJudgementBase]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f8f6e32",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the datasets\n",
    "### CQADupStack contains 12 datasets that will be loaded and merged:\n",
    "- Android\n",
    "- English\n",
    "- Gaming\n",
    "- GIS\n",
    "- Mathematica\n",
    "- Physics\n",
    "- Programmers\n",
    "- Stats\n",
    "- TeX\n",
    "- Unix\n",
    "- Webmasters\n",
    "- WordPress\n",
    "\n",
    "For more details: <a href=http://nlp.cis.unimelb.edu.au/resources/cqadupstack/>CQADupStack site</a>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pv211_utils.datasets import CQADupStackDataset \n",
    "\n",
    "data = CQADupStackDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8649d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data.load_documents(document_class=Document)\n",
    "\n",
    "train_queries = data.load_train_queries(query_class=Query)\n",
    "train_judgements = data.load_train_judgements()\n",
    "\n",
    "validation_queries = data.load_validation_queries(query_class=Query)\n",
    "validation_judgements = data.load_validation_judgements()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "260bf4a9",
   "metadata": {},
   "source": [
    "### Implementation of information retrieval system\n",
    "\n",
    "If you wish you might use [preprocessing](https://github.com/MIR-MU/pv211-utils/tree/main/pv211_utils/preprocessing) or [ensemble](https://github.com/MIR-MU/pv211-utils/blob/developer/pv211_utils/ensembles.py) techniques from our library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e66f8a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pv211_utils.beir.irsystem import BeirIRSystemBase\n",
    "from pv211_utils.systems.bm25 import BM25PlusSystem\n",
    "from pv211_utils.preprocessing.preprocessing import NoneDocPreprocessing\n",
    "from typing import Iterable\n",
    "\n",
    "class IRSystem(BeirIRSystemBase):\n",
    "   def __init__(self) -> None:\n",
    "       self.bm25_system = BM25PlusSystem(documents=documents, preprocessing=NoneDocPreprocessing()) \n",
    "    \n",
    "   def search(self, query: Query) -> Iterable[Document]:\n",
    "      return self.bm25_system.search(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "EiuNlaI76EPe",
   "metadata": {
    "id": "EiuNlaI76EPe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate the system on a given dataset\n",
    "\n",
    "We will evaluate the IR system using the [Mean Average Precision](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision) (MAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pv211_utils.beir.leaderboard import BeirLeaderboard \n",
    "from pv211_utils.beir.eval import BeirEvaluation \n",
    "\n",
    "submit_result = False\n",
    "author_name = 'Surname, Name'\n",
    "\n",
    "print('Initializing your system ...')\n",
    "system = IRSystem()\n",
    "\n",
    "test_queries = data.load_test_queries()\n",
    "test_judgements = data.load_test_judgements()\n",
    "\n",
    "evaluation = BeirEvaluation(system, test_judgements, k=10, leaderboard=BeirLeaderboard(), author_name=author_name, num_workers=1)\n",
    "evaluation.evaluate(test_queries, submit_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81553327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TermFrequency-InverseDocumentFrequency_example.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "97b31d6e62de2216a05dd9342162045e53cee058ed98d00a361b193ba69cab9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
