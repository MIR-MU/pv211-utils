{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfQo2UKpZ9jT"
   },
   "source": [
    "# Alternative Second Term Project: ARQMath Collection, Answer Retrieval Task\n",
    "\n",
    "‚ÄúIn a recent study, Mansouri et al. found that 20% of mathematical queries in a general-purpose search engine were expressed as well-formed questions, a rate ten times higher than that for all queries submitted. Results such as these and the presence of Community Question Answering sites such as Math Stack Exchange suggest there is interest in finding answers to mathematical questions posed in natural language, using both text and mathematical notation.‚Äù [1]\n",
    "\n",
    "‚Äú[ARQMath](https://www.cs.rit.edu/~dprl/ARQMath/) is a co-operative evaluation exercise aiming to advance math-aware search and the semantic analysis of mathematical notation and texts. **ARQMath is being run for the second time at CLEF 2021.** An overview paper (including results) from ARQMath 2020 is available along with participant papers in the [CLEF 2020 working notes](http://ceur-ws.org/Vol-2696).‚Äù [2]\n",
    "\n",
    " ![Answer Retrieval Task](https://www.cs.rit.edu/~dprl/ARQMath/assets/images/screen-shot-2019-09-09-at-11.11.57-pm-2656x1229.png)\n",
    "\n",
    "Your tasks, reviewed by your colleagues and the course instructors, are the following:\n",
    "\n",
    "1.   *Implement a supervised ranked retrieval system*, [3, Chapter¬†15] which will produce a list of documents from the TREC collection in a descending order of relevance to a query from the TREC collection. You SHOULD use training and validation relevance judgements from the TREC collection in your information retrieval system. Test judgements MUST only be used for the evaluation of your information retrieval system.\n",
    "\n",
    "2.   *Document your code* in accordance with [PEP 257](https://www.python.org/dev/peps/pep-0257/), ideally using [the NumPy style guide](https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard) as seen in the code from exercises.  \n",
    "     *Stick to a consistent coding style* in accordance with [PEP 8](https://www.python.org/dev/peps/pep-0008/).\n",
    "\n",
    "3.   *Reach at least 1.2% mean average precision* [3, Section¬†8.4] with your system on the Trec collection. You are encouraged to use techniques for tokenization, [3, Section¬†2.2] document representation [3, Section¬†6.4], tolerant retrieval [3, Chapter¬†3], relevance feedback, query expansion, [3, Chapter¬†9], learning to rank [3, Chapter 15], and others discussed in the course.\n",
    "\n",
    "4.   _[Upload an .ipynb file](https://is.muni.cz/help/komunikace/spravcesouboru#k_ss_1) with this Jupyter notebook to the homework vault in IS MU._ You MAY also include a brief description of your information retrieval system and a link to an external service such as [Google Colaboratory](https://colab.research.google.com/), [DeepNote](https://deepnote.com/), or [JupyterHub](https://iirhub.cloud.e-infra.cz/).\n",
    "\n",
    "The best student systems will enter the ARQMath competition and help develop the new search engine for [the Math StackExchange question answering forum](http://math.stackexchange.com/). This is not only useful, but also a nice reference for your CVs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruSklUM7e5aj"
   },
   "source": [
    "[1] Zanibbi, R. et al. [Overview of ARQMath 2020 (Updated Working Notes Version): CLEF Lab on Answer Retrieval for Questions on Math](http://ceur-ws.org/Vol-2696/paper_271.pdf). In: *Working Notes of CLEF 2020-Conference and Labs of the Evaluation Forum*. 2020.\n",
    "\n",
    "[2] Zanibbi, R. et al. [*ARQMath: Answer Retrieval for Questions on Math*](https://www.cs.rit.edu/~dprl/ARQMath/index.html). Rochester Institute of Technology. 2021.\n",
    "\n",
    "[3] Manning, Christopher D., Prabhakar Raghavan, and Hinrich Sch√ºtze. [*Introduction to information retrieval*](https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf). Cambridge university press, 2008."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmpR8qpTZwyP"
   },
   "source": [
    "## Loading the ARQMath collection\n",
    "\n",
    "First, we will install [our library](https://gitlab.fi.muni.cz/xstefan3/pv211-utils) and load the ARQMath collection. If you are interested, you can take a peek at [how we preprocessed the raw ARQMath collection](https://drive.google.com/file/d/1ZFJyBHUuMe4CkwV1HGKYg_F-Fk_PSW9R/view) to the final dataset that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "inUAfc6TQMVJ"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install git+https://github.com/MIR-MU/pv211-utils.git\n",
    "! pip install gensim==3.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdM90O8nlUn5"
   },
   "source": [
    "#\n",
    "#The questions and answers from the ARQMath collection, and the queries from the from the answer retrieval task of ARQMath 2020 contain both text and mathematical formulae. We have prepared several encodings of the text and mathematical, which you can choose from:\n",
    "\n",
    "- `text` ‚Äì Plain text, which contains no mathematical formulae. *Nice and easy*, but you are losing all information about the math:\n",
    "\n",
    "    > Finding value of  such that ...\n",
    "\n",
    "- `text+latex` ‚Äì Plain text with mathematical formulae in LaTeX surrounded by dollar signs. Still quite nice to work:\n",
    "\n",
    "    > Finding value of \\$c\\$ such that ...\n",
    "\n",
    "- `text+tangentl` ‚Äì Plain text with mathematical formulae in [the mathtuples format][5] of [the Tangent-L system][6]. Like LaTeX, the mathtuples format encodes how a mathematical formula looks, but is fuzzier in order to improve recall.\n",
    "\n",
    "    > Finding value of #(start)# #(v!c,!0,-)# #(v!c,!0)# #(end)# such that ...\n",
    "\n",
    "- `text+prefix` ‚Äì Plain text with mathematical formulae in [the prefix format][1]. Unlike LaTeX, which encodes how a mathematical formula looks, the prefix format encodes the semantic content of the formulae using [the Polish notation][2].\n",
    "\n",
    "    > Finding value of V!ùëê such that ...\n",
    "\n",
    "- `xhtml+latex` ‚Äì XHTML text with mathematical formulae in LaTeX, surrounded by the `<span class=\"math-container\">` tags:\n",
    "\n",
    "    > ``` html\n",
    "    > <p>Finding value of <span class=\"math-container\">$c$</span> such that ...\n",
    "    > ```\n",
    "\n",
    "- `xhtml+pmml` ‚Äì XHTML text with mathematical formulae in the [Presentation MathML][4] XML format, which encodes how a mathematical formula looks:\n",
    "\n",
    "    > ``` html\n",
    "    > <p>Finding value of <math><mi>c</mi></math> such that'\n",
    "    > ```\n",
    "\n",
    "- `xhtml+cmml` ‚Äì XHTML text with mathematical formulae in the [Content MathML][3] XML format, which encodes the semantic content of a formula. This format is *much more difficult to work with*, but it allows you to represent mathematical formulae structurally and use XML Retrieval [3, Chapter 10].\n",
    "\n",
    "    > ``` html\n",
    "    > <p>Finding value of <math><ci>ùëê</ci></math> such that ...\n",
    "    > ```\n",
    "\n",
    " [1]: http://ceur-ws.org/Vol-2696/paper_235.pdf#page=5\n",
    " [2]: https://en.wikipedia.org/wiki/Polish_notation\n",
    " [3]: https://www.w3.org/TR/MathML2/chapter4.html\n",
    " [4]: https://www.w3.org/TR/MathML2/chapter3.html\n",
    " [5]: https://github.com/fwtompa/mathtuples\n",
    " [6]: http://ceur-ws.org/Vol-2936/paper-05.pdf#page=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "azYtWfRRpoxB"
   },
   "outputs": [],
   "source": [
    "text_format = 'text'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y845E0ePZqeH"
   },
   "source": [
    "### Loading the answers\n",
    "\n",
    "Next, we will define a class named `Answer` that will represent a preprocessed answer from the ARQMath 2020 collection. Tokenization and preprocessing of the `body` attribute of the individual answers as well as the creative use of the `upvotes` and `is_accepted` attributes is left to your imagination and craftsmanship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "fyAqWIQyINng"
   },
   "outputs": [],
   "source": [
    "from pv211_utils.arqmath.entities import ArqmathAnswerBase\n",
    "\n",
    "class Answer(ArqmathAnswerBase):\n",
    "    \"\"\"A preprocessed answer from the ARQMath 2020 collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document_id : str\n",
    "        A unique identifier of the answer among all questions and answers.\n",
    "    body : str\n",
    "        The text of the answer, including mathematical formulae.\n",
    "    upvotes : int\n",
    "        The number of upvotes for the answer.\n",
    "    is_accepted : bool\n",
    "        If the answer has been accepted by the poster of the question.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, document_id: str, body: str, upvotes: int,\n",
    "                 is_accepted: bool):\n",
    "        # preprocessing?\n",
    "        super().__init__(document_id, body, upvotes, is_accepted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwnMPmFjK_FQ"
   },
   "source": [
    "We will load answers into the `answers` [ordered dictionary](https://docs.python.org/3.8/library/collections.html#collections.OrderedDict). Each answer is an instance of the `Answer` class that we have just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "HfRrW7O6U5wb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text+latex.json.gz\n"
     ]
    }
   ],
   "source": [
    "from pv211_utils.arqmath.loader import load_answers\n",
    "from pv211_utils.datasets import ArqmathDataset\n",
    "data = ArqmathDataset(year=2021, text_format=text_format)\n",
    "answers = data.load_answers(answer_class = Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "DkeKUsWWWnb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document 4 ‚ÄúMore or Less is a BBC Radio 4 programme about math ...‚Äù>\n",
      "<Document 7 ‚ÄúYou use a proof by contradiction. Basically, you s ...‚Äù>\n",
      "<Document 9 ‚ÄúSuppose no one ever taught you the names for ordin ...‚Äù>\n",
      "...\n",
      "<Document 3058133 ‚ÄúFirst take some $v \\in \\mathbb{C}^3$ such that $(A ...‚Äù>\n",
      "<Document 3058134 ‚ÄúThe answer is NO. Take $m=1$ and $\\Omega=(0,2\\pi)$ ...‚Äù>\n",
      "<Document 3058136 ‚ÄúFirstly, it‚Äôs trivial that $f(0) = f(4\\cdot 0\\cdot ...‚Äù>\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(repr(answer) for answer in list(answers.values())[:3]))\n",
    "print('...')\n",
    "print('\\n'.join(repr(answer) for answer in list(answers.values())[-3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PxiK4MFqwCM"
   },
   "source": [
    "For a demonstration, we will load [the accepted answer from the image above][1].\n",
    "\n",
    " [1]: https://math.stackexchange.com/a/30741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "kvsnuhT3ZZAo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Document 30741 ‚ÄúNo need to use Taylor series, this can be derived  ...‚Äù>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = answers['30741']\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "W3z7ed8SZkn6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No need to use Taylor series, this can be derived in a similar way to the formula for geometric series. Let's find a general formula for the following sum: $S_{m}=\\sum_{n=1}^{m}nr^{n}.$   Notice that  \\begin{align*} S_{m}-rS_{m} & = -mr^{m+1}+\\sum_{n=1}^{m}r^{n}\\\\   & = -mr^{m+1}+\\frac{r-r^{m+1}}{1-r} \\\\ & =\\frac{mr^{m+2}-(m+1)r^{m+1}+r}{1-r}. \\end{align*} Hence  $S_m = \\frac{mr^{m+2}-(m+1)r^{m+1}+r}{(1-r)^2}.$ This equality holds for any $r$, but in your case we have $r=\\frac{1}{3}$ and a factor of $\\frac{2}{3}$ in front of the sum.    That is  \\begin{align*} \\sum_{n=1}^{\\infty}\\frac{2n}{3^{n+1}}  & = \\frac{2}{3}\\lim_{m\\rightarrow\\infty}\\frac{m\\left(\\frac{1}{3}\\right)^{m+2}-(m+1)\\left(\\frac{1}{3}\\right)^{m+1}+\\left(\\frac{1}{3}\\right)}{\\left(1-\\left(\\frac{1}{3}\\right)\\right)^{2}} \\\\ & =\\frac{2}{3}\\frac{\\left(\\frac{1}{3}\\right)}{\\left(\\frac{2}{3}\\right)^{2}} \\\\ & =\\frac{1}{2}. \\end{align*}  Added note:    We can define $S_m^k(r) = \\sum_{n=1}^m n^k r^n.$  Then the sum above considered is $S_m^1(r)$, and the geometric series is $S_m^0(r)$.  We can evaluate $S_m^2(r)$ by using a similar trick, and considering $S_m^2(r) - rS_m^2(r)$.  This will then equal a combination of $S_m^1(r)$ and $S_m^0(r)$ which already have formulas for.    This means that given a $k$, we could work out a formula for $S_m^k(r)$, but can we find $S_m^k(r)$ in general for any $k$?  It turns out we can, and the formula is similar to the formula for $\\sum_{n=1}^m n^k$, and involves the Bernoulli numbers. In particular, the denominator is $(1-r)^{k+1}$.\n"
     ]
    }
   ],
   "source": [
    "print(answer.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Arv8iIVcqrKa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n"
     ]
    }
   ],
   "source": [
    "print(answer.upvotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oyH47Fm2q_3J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(answer.is_accepted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjzTmnjcrJVQ"
   },
   "source": [
    "### Loading the questions\n",
    "\n",
    "Next, we will define a class named `Question` that will represent a preprocessed question from the ARQMath 2020 collection. Tokenization and preprocessing of the `title` and `body` attributes of the individual questions as well as the creative use of the `tags`, `upvotes`, `views`, and `answers` attributes is left to your imagination and craftsmanship.\n",
    "\n",
    "We will not be returning these questions from our search engine, but we could use them for example to look up similar existing questions to a query and then return the answers to these existing questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "w8pvrN22r7nD"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from pv211_utils.arqmath.entities import ArqmathQuestionBase\n",
    "\n",
    "class Question(ArqmathQuestionBase):\n",
    "    \"\"\"A preprocessed question from the ARQMath 2020 collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document_id : str\n",
    "        A unique identifier of the question among all questions and answers.\n",
    "    title : str\n",
    "        The title of the question, including mathematical formulae.\n",
    "    body : str\n",
    "        The text of the question, including mathematical formulae.\n",
    "    tags : list of str\n",
    "        Tags describing the topics of the question.\n",
    "    upvotes : int\n",
    "        The number of upvotes for the question.\n",
    "    views : int\n",
    "        The number of views for the question.\n",
    "    answers : list of Answer\n",
    "        The answers for the question.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, document_id: str, title: str, body: str, tags: List[str],\n",
    "                 upvotes: int, views: int, answers: List[Answer]):\n",
    "        # preprocessing?!\n",
    "        super().__init__(document_id, title, body, tags, upvotes, views, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHOV8rOIsZI7"
   },
   "source": [
    "We will load answers into the `questions` [ordered dictionary](https://docs.python.org/3.8/library/collections.html#collections.OrderedDict). Each answer is an instance of the `Question` class that we have just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uUgfKxugscxo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n",
      "Computing MD5: /var/tmp/pv211/arqmath2020_questions_text.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_questions_text.json.gz\n"
     ]
    }
   ],
   "source": [
    "from pv211_utils.arqmath.loader import load_questions\n",
    "\n",
    "questions = data.load_questions(question_class=Question)\n",
    "answer_to_question = {\n",
    "    answer: question\n",
    "    for question in questions.values()\n",
    "    for answer in question.answers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "47cK1-i7tWoq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document 1 ‚ÄúCan someone explain to me how there can be differe ...‚Äù>\n",
      "<Document 3 ‚Äúmathfactor is one I listen to. Does anyone else ha ...‚Äù>\n",
      "<Document 5 ‚ÄúI have read a few proofs that is irrational. I hav ...‚Äù>\n",
      "...\n",
      "<Document 3058122 ‚ÄúOn have the spherical parametrization . Is it mean ...‚Äù>\n",
      "<Document 3058135 ‚ÄúI had a question in my exam and they asked to prov ...‚Äù>\n",
      "<Document 3062816 ‚ÄúI was trying to solve the following problem: Let b ...‚Äù>\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(repr(question) for question in list(questions.values())[:3]))\n",
    "print('...')\n",
    "print('\\n'.join(repr(question) for question in list(questions.values())[-3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUc27QKesuZT"
   },
   "source": [
    "For a demonstration, we will load [the question from the image above][1].\n",
    "\n",
    " [1]: https://math.stackexchange.com/q/30732"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3BGh38LstRJy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Document 30732 ‚ÄúHow can I evaluate ? I know the answer thanks to W ...‚Äù>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = questions['30732']\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0xPByCB0tdZc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I evaluate ?\n"
     ]
    }
   ],
   "source": [
    "print(question.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OqMdpSa4thSG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I evaluate ? I know the answer thanks to Wolfram Alpha, but I'm more concerned with how I can derive that answer. It cites tests to prove that it is convergent, but my class has never learned these before. So I feel that there must be a simpler method.  In general, how can I evaluate\n"
     ]
    }
   ],
   "source": [
    "print(question.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "T008FvcWtlNQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sequences-and-series', 'convergence-divergence', 'power-series', 'faq']\n"
     ]
    }
   ],
   "source": [
    "print(question.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1iYJlfyEtnHM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "print(question.upvotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mjC3WLrMtpS8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37953\n"
     ]
    }
   ],
   "source": [
    "print(question.views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Xf3d7pFatrlH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Document 30741 ‚ÄúNo need to use Taylor series, this can be derived  ...‚Äù>, <Document 223857 ‚ÄúIf you want a solution that doesn't require deriva ...‚Äù>, <Document 30746 ‚ÄúAs indicated in other answers, you can reduce this ...‚Äù>, <Document 30747 ‚ÄúFactor out the . Then write It is easy to show tha ...‚Äù>, <Document 81635 ‚ÄúMy favorite proof of this is in this paper of Roge ...‚Äù>, <Document 30734 ‚ÄúHints You know (don't you?) the formula for for Ta ...‚Äù>, <Document 223850 ‚ÄúNote that , i.e., a geometric series, which conver ...‚Äù>, <Document 30736 ‚ÄúYou can find by differentiation. Just notice that  ...‚Äù>, <Document 539711 ‚ÄúConsider the generating function If we let , then  ...‚Äù>, <Document 548068 ‚ÄúLet be It's easy to prove that for , the sums sati ...‚Äù>, <Document 879374 ‚ÄúIn fact, For , we have‚Äù>, <Document 639269 ‚ÄúNote that is the number ways to choose items of ty ...‚Äù>, <Document 820130 ‚ÄúI assume that the to be less than . Now, consider, ...‚Äù>, <Document 1063667 ‚ÄúI first encountered this sum with the following pr ...‚Äù>, <Document 1706005 ‚ÄúTo avoid differentiating an infinite sum. We start ...‚Äù>, <Document 1290618 ‚ÄúOne method of evaluating can be like this, we take ...‚Äù>, <Document 2173698 ‚ÄúNo one like finite calculus notation? Unbelievable ...‚Äù>, <Document 2664979 ‚Äú\\begin{align} \\sum_{n=0}^\\infty (n+1)x^n &= \\sum_{ ...‚Äù>, <Document 2739692 ‚ÄúSolving for all gives and . Therefore, Using and t ...‚Äù>]\n"
     ]
    }
   ],
   "source": [
    "print(question.answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YLVh6NumtyRb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Document 30741 ‚ÄúNo need to use Taylor series, this can be derived  ...‚Äù>]\n"
     ]
    }
   ],
   "source": [
    "print([answer for answer in question.answers if answer.is_accepted])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwYwHs-MpD1_"
   },
   "source": [
    "### Loading the queries\n",
    "Next, we will define a class named `Query` that will represent a preprocessed query from the answer retrieval task of ARQMath 2020. Tokenization and preprocessing of the `title` and `body` attributes of the individual questions as well as the creative use of the `tags` attribute is left to your imagination and craftsmanship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oaCFkMFdKjST"
   },
   "outputs": [],
   "source": [
    "from pv211_utils.arqmath.entities import ArqmathQueryBase\n",
    "\n",
    "class Query(ArqmathQueryBase):\n",
    "    \"\"\"A preprocessed query from the answer retrieval task of ARQMath 2020.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query_id : int\n",
    "        A unique identifier of the query.\n",
    "    title : str\n",
    "        The title of the query, including mathematical formulae.\n",
    "    body : str\n",
    "        The text of the query, including mathematical formulae.\n",
    "    tags : list of str\n",
    "        Tags describing the topics of the query.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, query_id: int, title: str, body: str, tags: List[str]):\n",
    "        # preprocessing!\n",
    "        super().__init__(query_id, title, body, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-aAREbRMXeJ"
   },
   "source": [
    "We will load queries into the `train_queries` and `validation_queries` [ordered dictionaries](https://docs.python.org/3.8/library/collections.html#collections.OrderedDict). Each query is an instance of the `Query` class that we have just defined. You should use `train_queries`, `validation_queries`, and *relevance judgements* (see the next section) for training your supervised information retrieval system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciMVC1ufImzf"
   },
   "source": [
    "If you are training just a single machine learning model without any early stopping or hyperparameter optimization, you can use `bigger_train_queries` as the input.\n",
    "\n",
    "If you are training a single machine learning model with early stopping or hyperparameter optimization, you can use `train_queries` for training your model and `validation_queries` to stop early or to select the optimal hyperparameters for your model. You can then use `bigger_train_queries` to train the model with the best number of epochs or the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8qcyQUNRqRTr"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "\n",
    "train_queries = data.load_train_queries(query_class=Query)\n",
    "validation_queries = data.load_validation_queries(query_class=Query)\n",
    "\n",
    "bigger_train_queries = OrderedDict(chain(train_queries.items(), validation_queries.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "IW-N6g3LqwPZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Query 18 ‚ÄúEvaluate using Ces√°ro-Stolz theorem. I know there  ...‚Äù>\n",
      "<Query 89 ‚ÄúIs there any known complete parametrization of the ...‚Äù>\n",
      "<Query 49 ‚ÄúI came across an exercise in which we are asked to ...‚Äù>\n",
      "...\n",
      "<Query 303 ‚ÄúTheorem- Up to isomorphism, the only noncommutativ ...‚Äù>\n",
      "<Query 373 ‚ÄúShow that is irrational if is notperfect square, u ...‚Äù>\n",
      "<Query 374 ‚ÄúFind all monic complex polynomials such that . My  ...‚Äù>\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(repr(query) for query in list(train_queries.values())[:3]))\n",
    "print('...')\n",
    "print('\\n'.join(repr(query) for query in list(train_queries.values())[-3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SA-0vN4swjwD"
   },
   "source": [
    "For a demonstration, we will look at query number 5. This is a query that is relatively easy to answer using just the text of the query, not the mathematical formulae. The user is asking for a computational solution to an interesting puzzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "VgdHjSYIq5HV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Query 5 ‚ÄúA family has two children. Given that one of the c ...‚Äù>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = validation_queries[5]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "w4NGZOdOq8NF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A family has two children. Given that one of the children is a boy, what is the probability that both children are boys?\n"
     ]
    }
   ],
   "source": [
    "print(query.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "m6u1D5sgHFdy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A family has two children. Given that one of the children is a boy, what is the probability that both children are boys?   I was doing this question using conditional probability formula.   Suppose, (1) is the event, that the first child is a boy, and (2) is the event that the second child is a boy.  Then the probability of the second child to be boy given that first child is a boys by formula,  ...since second child to be boy doesn't depend on first child and vice versa. Please provide the detailed solution and correct me if I am wrong.\n"
     ]
    }
   ],
   "source": [
    "print(query.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "QKiDvbPZHG0n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['probability', 'proof-verification', 'conditional-probability']\n"
     ]
    }
   ],
   "source": [
    "print(query.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8psrfOlGH-hM"
   },
   "source": [
    "### Loading the relevance judgements\n",
    "Next, we will load train and validation relevance judgements into the `train_judgements` and `validation_judgement` sets. Relevance judgements specify, which answers are relevant to which queries. You should use relevance judgements for training your supervised information retrieval system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zzV99yDIrJf"
   },
   "source": [
    "\n",
    "If you are training just a single machine learning model without any early stopping or hyperparameter optimization, you can use `bigger_train_judgements` as the input.\n",
    "\n",
    "If you are training a single machine learning model with early stopping or hyperparameter optimization, you can use `train_judgements` for training your model and `validation_judgements` to stop early or to select the optimal hyperparameters for your model. You can then use `bigger_train_judgements` to train the model with the best number of epochs or the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "MbEYf0zwKz44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n",
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n",
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n",
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n"
     ]
    }
   ],
   "source": [
    "from pv211_utils.arqmath.loader import load_judgements\n",
    "\n",
    "train_judgements = data.load_train_judgements()\n",
    "validation_judgements = data.load_validation_judgements()\n",
    "\n",
    "bigger_train_judgements = train_judgements | validation_judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vu2ynv-BcK3O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4747"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigger_train_judgements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3I5Wv_9ynfI"
   },
   "source": [
    "For a demonstration, we will look at query number 5 and show a relevant answer to the query and a non-relevant answer to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MbRB48vRLF4k"
   },
   "outputs": [],
   "source": [
    "query = validation_queries[5]\n",
    "relevant_answer = answers['1037824']\n",
    "irrelevant_answer = answers['432200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "C7oapMQvLqZ6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Query 5 ‚ÄúA family has two children. Given that one of the c ...‚Äù>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "iCsjADYbLsR2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Document 1037824 ‚ÄúIf he has more daughters than sons, Below are the  ...‚Äù>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "r2BRSpkELsTv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Document 432200 ‚ÄúIt is interesting that everyone is considering tha ...‚Äù>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrelevant_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2-AizE1_Lnto"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(query, relevant_answer) in train_judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "fZe8KKNcLx3X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(query, irrelevant_answer) in train_judgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJM9TfbEPCZV"
   },
   "source": [
    "## Implementation of your information retrieval system\n",
    "Next, we will define a class named `IRSystem` that will represent your information retrieval system. Your class must define a method name `search` that takes a query and returns answers in descending order of relevance to the query.\n",
    "\n",
    "The example implementation returns answers in decreasing order of the TF-IDF cosine similarity between the answer and the query. You can use the example implementation as a basis of your system, or you can replace it with your own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Bqq_dijKRT-F"
   },
   "outputs": [],
   "source": [
    "from multiprocessing import get_context\n",
    "from typing import Iterable, Union, List, Tuple\n",
    "\n",
    "from pv211_utils.arqmath.irsystem import ArqmathIRSystemBase\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.matutils import cossim\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.similarities import SparseMatrixSimilarity\n",
    "from gensim.utils import simple_preprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "class IRSystem(ArqmathIRSystemBase):\n",
    "    \"\"\"\n",
    "    A system that returns answers ordered by decreasing cosine similarity.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    dictionary: Dictionary\n",
    "        The dictionary of the system.\n",
    "    tfidf_model: TfidfModel\n",
    "        The TF-IDF model of the system.\n",
    "    index: MatrixSimilarity\n",
    "        The indexed TF-IDF answers.\n",
    "    index_to_answer: dict of (int, Answer)\n",
    "        A mapping from indexed answer numbers to answers.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        with get_context('fork').Pool(None) as pool:\n",
    "            answer_bodies = pool.imap(self.__class__._document_to_tokens, answers.values())\n",
    "            answer_bodies = tqdm(answer_bodies, desc='Building the dictionary', total=len(answers))\n",
    "            self.dictionary = Dictionary(answer_bodies)\n",
    "            self.__class__.DICTIONARY = self.dictionary\n",
    "\n",
    "        with get_context('fork').Pool(None) as pool:\n",
    "            answer_vectors = pool.imap(self.__class__._document_to_bag_of_words, answers.values())\n",
    "            answer_vectors = tqdm(answer_vectors, desc='Building the TF-IDF model', total=len(answers))\n",
    "            self.tfidf_model = TfidfModel(answer_vectors)\n",
    "            self.__class__.TFIDF_MODEL = self.tfidf_model\n",
    "\n",
    "        with get_context('fork').Pool(None) as pool:\n",
    "            answer_vectors = pool.imap(self.__class__._document_to_tfidf_vector, answers.values())\n",
    "            answer_vectors = tqdm(answer_vectors, desc='Building the TF-IDF index', total=len(answers))\n",
    "            self.index = SparseMatrixSimilarity(answer_vectors, num_docs=len(answers), num_terms=len(self.dictionary))\n",
    "        \n",
    "        del self.__class__.DICTIONARY\n",
    "        del self.__class__.TFIDF_MODEL\n",
    "\n",
    "        self.index_to_answer = dict(enumerate(answers.values()))\n",
    "\n",
    "    def search(self, query: Query) -> Iterable[Answer]:\n",
    "        \"\"\"The ranked retrieval results for a query.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        query : Query\n",
    "            A query.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        iterable of Document\n",
    "            The ranked retrieval results for a query.\n",
    "\n",
    "        \"\"\"\n",
    "        self.__class__.DICTIONARY = self.dictionary\n",
    "        self.__class__.TFIDF_MODEL = self.tfidf_model\n",
    "\n",
    "        query_vector = self.__class__._document_to_tfidf_vector(query)\n",
    "        similarities = enumerate(self.index[query_vector])\n",
    "        similarities = sorted(similarities, key=lambda item: item[1], reverse=True)\n",
    "        for answer_number, _ in similarities:\n",
    "            answer = self.index_to_answer[answer_number]\n",
    "            yield answer\n",
    "        \n",
    "        del self.__class__.DICTIONARY\n",
    "        del self.__class__.TFIDF_MODEL\n",
    "\n",
    "    @classmethod\n",
    "    def _document_to_tokens(cls, document: Union[Query, Answer]) -> List[str]:\n",
    "        return simple_preprocess(document.body)\n",
    "    \n",
    "    @classmethod\n",
    "    def _document_to_bag_of_words(cls, document: Union[Query, Answer]) -> List[Tuple[int, int]]:\n",
    "        return cls.DICTIONARY.doc2bow(cls._document_to_tokens(document))\n",
    "    \n",
    "    @classmethod\n",
    "    def _document_to_tfidf_vector(cls, document: Union[Query, Answer]) -> List[Tuple[int, float]]:\n",
    "        return cls.TFIDF_MODEL[cls._document_to_bag_of_words(document)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwrCzoaZhWi4"
   },
   "source": [
    "## Evaluation\n",
    "Finally, we will evaluate your information retrieval system using [the Mean Average Precision](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision) (MAP) evaluation measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ssX-nvxGu3JK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing your system ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building the dictionary: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1445495/1445495 [05:30<00:00, 4368.25it/s]\n",
      "Building the TF-IDF model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1445495/1445495 [06:20<00:00, 3797.15it/s]\n",
      "Building the TF-IDF index: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1445495/1445495 [15:43<00:00, 1532.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MD5: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n",
      "MD5 matches: /var/tmp/pv211/arqmath2020_answers_text.json.gz\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Your system achieved **2.30% MAP score**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Congratulations, you passed the **1.2%** minimum! ü•≥"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Set `submit_result = True` and write your name to the `author_name` variable to submit your result to [the leaderboard](https://docs.google.com/spreadsheets/d/e/2PACX-1vSOonHEUy1x-5othNd5ZmlxfqSi2p5pwgr5Rm6RU2U4HTOidiXvIWKwtb_LPfFmal6TvVjISGzIuczk/pubhtml). üèÜ\n",
       "\n",
       "The best submissions on the leaderboard will receive *small awards during the semester*, and some *__seriously big__ awards* after the personal check at the end of the competition (2023-04-30). Please be polite, do not spoil the game for the others, and **have fun!** üòâ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pv211_utils.arqmath.leaderboard import ArqmathLeaderboard\n",
    "from pv211_utils.arqmath.eval import ArqmathEvaluation\n",
    "\n",
    "submit_result = False\n",
    "author_name = 'Surname, Name'\n",
    "\n",
    "print('Initializing your system ...')\n",
    "system = IRSystem()\n",
    "\n",
    "test_queries = data.load_test_queries(query_class=Query)\n",
    "test_judgements = data.load_test_judgements()\n",
    "evaluation = ArqmathEvaluation(system, test_judgements, 10, ArqmathLeaderboard(), author_name, num_workers=1)\n",
    "evaluation.evaluate(test_queries, submit_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xmpR8qpTZwyP",
    "y845E0ePZqeH",
    "gjzTmnjcrJVQ",
    "CwYwHs-MpD1_",
    "8psrfOlGH-hM",
    "xJM9TfbEPCZV"
   ],
   "name": "Alternative second term project (ARQMath) example solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "97b31d6e62de2216a05dd9342162045e53cee058ed98d00a361b193ba69cab9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
